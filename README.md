# ğŸ¤– Swagger Agent

[![Java](https://img.shields.io/badge/Java-21-orange.svg)](https://openjdk.java.net/projects/jdk/21/)
[![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.2.3-brightgreen.svg)](https://spring.io/projects/spring-boot)
[![Spring AI](https://img.shields.io/badge/Spring%20AI-0.8.0-blue.svg)](https://spring.io/projects/spring-ai)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Documentation](https://img.shields.io/badge/docs-swagger--agent-blue.svg)](https://cesarschutz.github.io/swagger-agent/)

<p align="center">
  <img src="src/main/resources/static/img/logo.png" alt="Swagger Agent Logo" width="200"/>
</p>

<p align="center">
  <strong>Transforme qualquer especificaÃ§Ã£o OpenAPI em ferramentas dinÃ¢micas que podem ser invocadas por modelos de linguagem (LLMs).</strong>
</p>

<p align="center">
  ConstruÃ­do com <strong>Spring Boot 3</strong>, <strong>Spring AI</strong> e preparado para rodar com <strong>OpenAI</strong> ou <strong>modelos locais via Ollama</strong>.
</p>

<p align="center">
  <a href="https://cesarschutz.github.io/swagger-agent/">ğŸ“š DocumentaÃ§Ã£o Completa</a>
</p>

## ğŸ“‘ Ãndice

- [âœ¨ Funcionalidades](#-funcionalidades)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ—ï¸ Arquitetura](#ï¸-arquitetura)
- [ğŸ¤– ConfiguraÃ§Ã£o de Provedores de IA](#-configuraÃ§Ã£o-de-provedores-de-ia)
- [ğŸ§‘â€ğŸ’» Usando com Modelo Local](#-usando-com-modelo-local-ollama)
- [ğŸ“š API Reference](#-api-reference)
- [ğŸ”§ ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [ğŸ¤ Contribuindo](#-contribuindo)
- [ğŸ“„ LicenÃ§a](#-licenÃ§a)

## âœ¨ Funcionalidades

### ğŸš€ Chat Inteligente
- ComunicaÃ§Ã£o natural com modelos da OpenAI ou LLMs locais via `/api/chat`
- MemÃ³ria de sessÃ£o para manter contexto entre conversas
- **Suporte a mÃºltiplos provedores de IA**: OpenAI e Ollama com troca fÃ¡cil via configuraÃ§Ã£o

### ğŸ–¥ï¸ Interface Web Moderna

<div align="center">
  <div style="margin-bottom: 2rem;">
    <h4>ğŸ–¥ï¸ Desktop</h4>
    <img src="src/main/resources/static/img/interfaceweb.png" alt="Interface Web do Swagger Agent" width="800"/>
  </div>
  
  <div>
    <h4>ğŸ“± Mobile</h4>
    <img src="src/main/resources/static/img/interfacewebmobile.png" alt="Interface Mobile do Swagger Agent" width="300"/>
  </div>
</div>

- **ğŸ¨ Design Moderno**: Interface com gradientes, efeitos glass e animaÃ§Ãµes suaves
- **ğŸ› ï¸ Painel de Ferramentas**: Visualize todas as APIs disponÃ­veis organizadas por projeto
- **ğŸ’¬ Chat Inteligente**: Conversa natural com suporte a markdown e emojis
- **ğŸ“± Responsivo**: Funciona perfeitamente em desktop, tablet e mobile
- **âš¡ Tempo Real**: Indicadores de digitaÃ§Ã£o e atualizaÃ§Ãµes instantÃ¢neas

### ğŸ› ï¸ Ferramentas DinÃ¢micas
- GeraÃ§Ã£o automÃ¡tica de functions a partir de arquivos OpenAPI
- ExecuÃ§Ã£o assÃ­ncrona para melhor responsividade
- Logs estruturados para auditoria

## ğŸš€ Quick Start (Usando OpenAI)

Siga os passos abaixo para executar o projeto com a configuraÃ§Ã£o padrÃ£o (OpenAI).

### ğŸ“‹ PrÃ©-requisitos
- **Java 21** ou superior
- **Maven 3.6+**
- **OpenAI API Key**

### âš¡ ExecuÃ§Ã£o

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone https://github.com/cesarschutz/swagger-agent.git
    cd swagger-agent
    ```

2.  **Adicione seus arquivos OpenAPI:**
    - Coloque seus arquivos de especificaÃ§Ã£o (`.json` ou `.yaml`) na pasta `openapi-specs/`. Por padrÃ£o, o projeto jÃ¡ inclui um exemplo do Petstore.

3.  **Configure sua chave da OpenAI:**
    ```bash
    export OPENAI_API_KEY="sua_chave_openai_aqui"
    ```

4.  **Execute a aplicaÃ§Ã£o:**
    ```bash
    ./mvnw spring-boot:run
    ```

5.  **Acesse a interface:**
    - Abra seu navegador em [http://localhost:8080/chat.html](http://localhost:8080/chat.html).

>ğŸ’¡ **Quer usar um modelo local?** Pule para a seÃ§Ã£o [Configurando o Provedor de IA](#-configurando-o-provedor-de-ia) para ver como usar o **Ollama**.

## ğŸ¤– Configurando o Provedor de IA

O Swagger Agent foi projetado para ser flexÃ­vel, permitindo que vocÃª alterne facilmente entre a **OpenAI** (padrÃ£o, baseado em nuvem) e o **Ollama** (para executar modelos de linguagem localmente). A seleÃ§Ã£o Ã© controlada pela propriedade `app.ai.provider` no arquivo `application.yml` ou pela variÃ¡vel de ambiente `AI_PROVIDER`.

Apenas um provedor de IA Ã© carregado em tempo de execuÃ§Ã£o, garantindo que nÃ£o haja sobrecarga ou conflitos.

---

### OpÃ§Ã£o 1: Usar OpenAI (PadrÃ£o)

Ideal para uma configuraÃ§Ã£o rÃ¡pida e para usar os modelos mais avanÃ§ados disponÃ­veis no mercado, exigindo apenas uma chave de API.

**1. Configure a Chave de API**
```bash
export OPENAI_API_KEY="sua_chave_openai_aqui"
```

**2. Defina o Provedor (Opcional)**
A propriedade jÃ¡ vem configurada por padrÃ£o para `openai`. Se precisar definir explicitamente:
```bash
# Via variÃ¡vel de ambiente
export AI_PROVIDER=openai

# Ou no application.yml
app:
  ai:
    provider: openai
```

**3. Execute**
```bash
./mvnw spring-boot:run
```

---

### OpÃ§Ã£o 2: Usar Modelo Local com Ollama

Perfeito para desenvolvimento offline, privacidade de dados ou para experimentar uma vasta gama de modelos de cÃ³digo aberto.

**1. Instale e Execute o Ollama**
A maneira mais fÃ¡cil Ã© usando Docker:
```bash
docker run -d --rm -p 11434:11434 --name ollama ollama/ollama
```

**2. Baixe um Modelo**
VocÃª precisa ter pelo menos um modelo baixado. Exemplo com `qwen2.5:0.5b`:
```bash
docker exec -it ollama ollama pull qwen2.5:0.5b
```

**3. Configure a AplicaÃ§Ã£o**
Informe Ã  aplicaÃ§Ã£o para usar o Ollama. VocÃª pode usar variÃ¡veis de ambiente (mais comum para dados sensÃ­veis ou que mudam com frequÃªncia) ou editar diretamente o `application.yml`.

*   **MÃ©todo 1: VariÃ¡veis de Ambiente**
    ```bash
    export AI_PROVIDER=ollama
    export SPRING_AI_OLLAMA_CHAT_OPTIONS_MODEL="qwen2.5:0.5b"
    export SPRING_AI_OLLAMA_BASE_URL=http://localhost:11434
    ```

*   **MÃ©todo 2: `application.yml`**
    ```yaml
    app:
      ai:
        provider: ollama
    spring:
      ai:
        ollama:
          base-url: http://localhost:11434
          chat:
            options:
              model: "qwen2.5:0.5b"
    ```

**4. Execute**
```bash
./mvnw spring-boot:run
```
> **Importante:** Lembre-se de reiniciar a aplicaÃ§Ã£o sempre que trocar o provedor de IA.

## ğŸ—ï¸ Arquitetura

O Swagger Agent funciona como uma ponte entre uma interface de chat, um modelo de linguagem e suas APIs existentes.

```mermaid
graph TD
    subgraph "Interface do UsuÃ¡rio"
        A[Frontend - chat.html]
    end

    subgraph "Backend (Swagger Agent)"
        B[Spring Boot Application]
        B -- Conecta --> C{Provedor de IA};
        B -- LÃª --> D[OpenAPI Specs];
        B -- Executa --> E[APIs Externas];
    end
    
    subgraph "ServiÃ§os de IA"
        C -- OpÃ§Ã£o 1 --> F[Cloud: OpenAI API]
        C -- OpÃ§Ã£o 2 --> G[Local: Ollama]
    end

    A <-->|RequisiÃ§Ãµes HTTP| B;
    D -- Gera --> B;
```

## ğŸ“š API Reference

| MÃ©todo | Endpoint         | DescriÃ§Ã£o                                                                              |
|--------|------------------|----------------------------------------------------------------------------------------|
| `POST` | `/api/chat`      | Envia uma mensagem para o chat. A resposta Ã© sÃ­ncrona.                                 |
| `POST` | `/api/chat/stream` | Envia uma mensagem e recebe a resposta em tempo real (streaming via Server-Sent Events). |
| `GET`  | `/api/tools`     | Lista todas as ferramentas dinÃ¢micas geradas a partir das especificaÃ§Ãµes OpenAPI.      |

### Exemplo: Chamada de Chat

```bash
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Quais pets estÃ£o disponÃ­veis para venda?",
    "sessionId": "conversa-unica-123"
  }'
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

A tabela abaixo resume as principais variÃ¡veis de ambiente que vocÃª pode usar para personalizar a aplicaÃ§Ã£o.

| VariÃ¡vel                              | DescriÃ§Ã£o                                                | PadrÃ£o                   |
|---------------------------------------|------------------------------------------------------------|--------------------------|
| `AI_PROVIDER`                         | Define o provedor de IA a ser usado (`openai` ou `ollama`). | `openai`                 |
| `OPENAI_API_KEY`                      | Sua chave de API da OpenAI.                                | N/A                      |
| `SPRING_AI_OLLAMA_BASE_URL`           | A URL base onde o servidor Ollama estÃ¡ rodando.            | `http://localhost:11434` |
| `SPRING_AI_OLLAMA_CHAT_OPTIONS_MODEL` | O nome do modelo que o Ollama deve usar para o chat.       | `qwen2.5:0.5b`             |

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Se vocÃª tiver ideias para novas funcionalidades, melhorias ou correÃ§Ãµes de bugs, sinta-se Ã  vontade para:

1.  Fazer um **fork** do repositÃ³rio.
2.  Criar uma nova **branch** (`git checkout -b feature/sua-feature`).
3.  Fazer **commit** de suas mudanÃ§as (`git commit -m 'Adiciona nova feature'`).
4.  Fazer **push** para a branch (`git push origin feature/sua-feature`).
5.  Abrir um **Pull Request**.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [LicenÃ§a MIT](LICENSE).

---

### ğŸ”— Links Ãšteis

- [ğŸ“š DocumentaÃ§Ã£o](https://cesarschutz.github.io/swagger-agent/)
- [ğŸ’» CÃ³digo Fonte](https://github.com/cesarschutz/swagger-agent)
- [ğŸ® Interface Demo](https://cesarschutz.github.io/swagger-agent/demo-chat.html)
